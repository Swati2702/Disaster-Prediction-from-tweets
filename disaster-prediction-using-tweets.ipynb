{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n",
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import regex as re\n",
    "from sklearn import linear_model\n",
    "import pdb\n",
    "from nltk.stem.porter import *\n",
    "import category_encoders as ce\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Forest fire near La Ronge Sask  Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>All residents asked to  shelter in place  are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNAVAILABLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword location                                               text\n",
       "0  UNAVAILABLE  UNKNOWN  Our Deeds are the Reason of this #earthquake M...\n",
       "1  UNAVAILABLE  UNKNOWN             Forest fire near La Ronge Sask  Canada\n",
       "2  UNAVAILABLE  UNKNOWN  All residents asked to  shelter in place  are ...\n",
       "3  UNAVAILABLE  UNKNOWN         people receive #wildfires evacuation or...\n",
       "4  UNAVAILABLE  UNKNOWN  Just got sent this photo from Ruby #Alaska as ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\n",
    "output = train_df['target']\n",
    "input_df = train_df.drop( ['id','target'], axis = 1)\n",
    "input_df['keyword'].fillna(\"UNAVAILABLE\", inplace = True)\n",
    "input_df['location'].fillna(\"UNKNOWN\", inplace = True)\n",
    "# remove user-names\n",
    "input_df['text'] = input_df['text'].str.replace(\"@[\\w]*\",\"\")\n",
    "# remove special characters, numbers, punctuations\n",
    "input_df['text'] = input_df['text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          our deed reason #earthquak may allah forgiv us\n",
       "1                    forest fire near La rong sask canada\n",
       "2       all resid ask shelter place notifi offic No ev...\n",
       "3            peopl receiv #wildfir evacu order california\n",
       "4       just got sent photo rubi #alaska smoke #wildfi...\n",
       "                              ...                        \n",
       "7608    two giant crane hold bridg collaps nearbi home...\n",
       "7609    the control wild fire california even northern...\n",
       "7610         M utc km S volcano hawaii http co zdtoyd ebj\n",
       "7611    polic investig e bike collid car littl portug ...\n",
       "7612    the latest more home raze northern california ...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = input_df['text'].apply(lambda x: x.split())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmed = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x if i not in stop_words])\n",
    "\n",
    "tweet = stemmed.apply(lambda x: ' '.join(x))\n",
    "\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Use TFIDF vectorizer to transform tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7613x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 41509 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tweet to tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf_tweet = tfidf_vectorizer.fit_transform(tweet)\n",
    "tfidf_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Use WOE encoder to encode keyword and location columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#woe encoder\n",
    "\n",
    "col_names = ['keyword', 'location']\n",
    "woe_encoder = ce.WOEEncoder(cols= col_names)\n",
    "woe_encoded_train = woe_encoder.fit_transform(input_df[col_names], output).add_suffix(\"woe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Train test split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_tweet, xvalid_tweet, ytrain_tweet, yvalid_tweet = train_test_split(tfidf_tweet, output, random_state=42, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Use ridge classifier to input tweets, use XGB regressor to input location and keyword and the output from these two models are fed to Ridge Classifier . This is the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RidgeClassifier()\n",
    "\n",
    "trained_tweet_model = clf.fit(xtrain_tweet,ytrain_tweet)\n",
    "trained_tweet_proba = trained_tweet_model.decision_function(xtrain_tweet)\n",
    "\n",
    "\n",
    "xtrain_lockey, xvalid_lockey, ytrain_lockey, yvalid_lockey = train_test_split(woe_encoded_train, output, random_state=42, test_size=0.3)\n",
    "\n",
    "clf = xgb.XGBRegressor(objective=\"binary:logistic\", random_state=42)\n",
    "trained_lockey_model = clf.fit(xtrain_lockey, ytrain_lockey)\n",
    "trained_lockey_proba = trained_lockey_model.predict(xtrain_lockey)\n",
    "\n",
    "#Merging\n",
    "next_input = zip(trained_tweet_proba, trained_lockey_proba)\n",
    "x = [data for data in list(next_input)]\n",
    "clf = linear_model.RidgeClassifier()\n",
    "trained_final_model = clf.fit(x, ytrain_tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Read test data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\n",
    "test['keyword'].fillna(\"UNAVAILABLE\", inplace=True)\n",
    "test['location'].fillna(\"UNKNOWN\", inplace=True)\n",
    "# remove user-names\n",
    "test['text'] = test['text'].str.replace(\"@[\\w]*\", \"\")\n",
    "# remove special characters, numbers, punctuations\n",
    "test['text'] = test['text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = test['text'].apply(lambda x: x.split())\n",
    "stemmed = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "\n",
    "tweet = stemmed.apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Use the trained model to predict whether the tweet is related to a disaster or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tweet to tfidf\n",
    "tfidf_tweet = tfidf_vectorizer.transform(tweet)\n",
    "\n",
    "\n",
    "col_names = ['keyword', 'location']\n",
    "test_lockey = woe_encoder.transform(test[col_names]).add_suffix(\"woe\")\n",
    "\n",
    "test_tweet_proba = trained_tweet_model.decision_function(tfidf_tweet)\n",
    "\n",
    "test_lockey_proba = trained_lockey_model.predict(test_lockey)\n",
    "\n",
    "# Merging\n",
    "next_input = zip(test_tweet_proba, test_lockey_proba)\n",
    "x = [data for data in next_input]\n",
    "out = trained_final_model.predict(x)\n",
    "\n",
    "test['target'] = out\n",
    "cols = ['id','target']\n",
    "test[cols].to_csv(\"submit.csv\", index = False)\n",
    "test[cols].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
